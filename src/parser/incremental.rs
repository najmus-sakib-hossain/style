//! Incremental HTML parser - only parses changed sections
//!
//! This module provides dramatic performance improvements for large HTML files
//! by only re-parsing the sections that actually changed, rather than the entire file.

use ahash::AHashSet;
use std::hash::Hasher;

use super::{ExtractedClasses, GroupEvent, extract_classes_fast};

/// Maximum size of change before falling back to full parse (bytes)
const MAX_INCREMENTAL_CHANGE_SIZE: usize = 8192; // 8KB

/// Minimum file size to enable incremental parsing (bytes)
const MIN_FILE_SIZE_FOR_INCREMENTAL: usize = 4096; // 4KB

/// Size of context window around changes (bytes)
const CHANGE_CONTEXT_SIZE: usize = 512;

/// Cached parse result for a file region
#[derive(Clone, Debug)]
struct RegionCache {
    /// Starting byte offset
    start: usize,
    /// Ending byte offset
    end: usize,
    /// Hash of content in this region
    #[allow(dead_code)]
    content_hash: u64,
    /// Classes found in this region
    classes: AHashSet<String>,
    /// Group events in this region
    group_events: Vec<GroupEvent>,
}

/// Incremental parser state
pub struct IncrementalParser {
    /// Previous file content hash
    prev_hash: u64,
    /// Previous file content
    prev_content: Vec<u8>,
    /// Cached regions from previous parse
    regions: Vec<RegionCache>,
    /// Statistics
    pub stats: IncrementalStats,
}

/// Statistics for incremental parsing
#[derive(Debug, Default, Clone)]
pub struct IncrementalStats {
    pub full_parses: usize,
    pub incremental_parses: usize,
    pub bytes_parsed: usize,
    pub bytes_skipped: usize,
    pub regions_reused: usize,
}

impl Default for IncrementalParser {
    fn default() -> Self {
        Self::new()
    }
}

impl IncrementalParser {
    /// Create a new incremental parser
    pub fn new() -> Self {
        Self {
            prev_hash: 0,
            prev_content: Vec::new(),
            regions: Vec::new(),
            stats: IncrementalStats::default(),
        }
    }

    /// Parse HTML incrementally, only re-parsing changed sections
    pub fn parse_incremental(
        &mut self,
        html_bytes: &[u8],
        capacity_hint: usize,
    ) -> ExtractedClasses {
        // Check if incremental parsing is disabled via environment variable
        if std::env::var("DX_DISABLE_INCREMENTAL").ok().as_deref() == Some("1") {
            self.stats.full_parses += 1;
            self.stats.bytes_parsed += html_bytes.len();
            let result = extract_classes_fast(html_bytes, capacity_hint);
            // Don't update cache when incremental is disabled
            return result;
        }

        // Quick hash to detect if anything changed
        let current_hash = {
            let mut hasher = ahash::AHasher::default();
            hasher.write(html_bytes);
            hasher.finish()
        };

        // If file is too small, always do full parse
        if html_bytes.len() < MIN_FILE_SIZE_FOR_INCREMENTAL {
            self.stats.full_parses += 1;
            self.stats.bytes_parsed += html_bytes.len();
            let result = extract_classes_fast(html_bytes, capacity_hint);
            self.update_cache(html_bytes, current_hash, &result);
            return result;
        }

        // If no previous content or hash matches, do full parse
        if self.prev_content.is_empty() || current_hash == self.prev_hash {
            if current_hash == self.prev_hash && !self.regions.is_empty() {
                // Content hasn't changed, return cached result
                return self.reconstruct_from_cache();
            }

            self.stats.full_parses += 1;
            self.stats.bytes_parsed += html_bytes.len();
            let result = extract_classes_fast(html_bytes, capacity_hint);
            self.update_cache(html_bytes, current_hash, &result);
            return result;
        }

        // Detect changed regions
        let changed_regions = self.detect_changes(html_bytes);

        // If changes are too extensive, fall back to full parse
        let total_change_size: usize = changed_regions.iter().map(|(s, e)| e - s).sum();
        if total_change_size > MAX_INCREMENTAL_CHANGE_SIZE || changed_regions.len() > 10 {
            self.stats.full_parses += 1;
            self.stats.bytes_parsed += html_bytes.len();
            let result = extract_classes_fast(html_bytes, capacity_hint);
            self.update_cache(html_bytes, current_hash, &result);
            return result;
        }

        // Perform incremental parse
        self.stats.incremental_parses += 1;
        let result = self.parse_changed_regions(html_bytes, &changed_regions, capacity_hint);
        self.update_cache(html_bytes, current_hash, &result);
        result
    }

    /// Detect which regions of the file changed
    fn detect_changes(&self, new_content: &[u8]) -> Vec<(usize, usize)> {
        let mut changes = Vec::new();

        // Use Myers' diff algorithm for efficient change detection
        let old = &self.prev_content;
        let new = new_content;

        // Simple line-based diff for efficiency
        let old_lines = split_into_lines(old);
        let new_lines = split_into_lines(new);

        let mut old_idx = 0;
        let mut new_idx = 0;
        let mut change_start = None;

        while old_idx < old_lines.len() || new_idx < new_lines.len() {
            if old_idx >= old_lines.len() {
                // Additions at end
                if change_start.is_none() {
                    change_start = Some(new_lines.get(new_idx).map(|l| l.0).unwrap_or(new.len()));
                }
                new_idx += 1;
            } else if new_idx >= new_lines.len() {
                // Deletions at end
                if change_start.is_none() {
                    change_start = Some(old_lines[old_idx].0.min(new.len()));
                }
                old_idx += 1;
            } else {
                let old_line = &old[old_lines[old_idx].0..old_lines[old_idx].1];
                let new_line = &new[new_lines[new_idx].0..new_lines[new_idx].1];

                if old_line == new_line {
                    // Lines match
                    if let Some(start) = change_start {
                        let end = new_lines[new_idx].1;
                        changes.push((start, end));
                        change_start = None;
                    }
                    old_idx += 1;
                    new_idx += 1;
                } else {
                    // Lines differ
                    if change_start.is_none() {
                        change_start = Some(new_lines[new_idx].0);
                    }

                    // Try to find matching line ahead
                    let mut found_match = false;
                    for lookahead in 1..5 {
                        if new_idx + lookahead < new_lines.len()
                            && old_idx + lookahead < old_lines.len()
                        {
                            let next_old = &old[old_lines[old_idx + lookahead].0
                                ..old_lines[old_idx + lookahead].1];
                            let next_new = &new[new_lines[new_idx + lookahead].0
                                ..new_lines[new_idx + lookahead].1];
                            if next_old == next_new {
                                found_match = true;
                                break;
                            }
                        }
                    }

                    if !found_match {
                        old_idx += 1;
                        new_idx += 1;
                    } else {
                        // Skip to match
                        new_idx += 1;
                    }
                }
            }
        }

        // Close final change region
        if let Some(start) = change_start {
            changes.push((start, new.len()));
        }

        // Expand regions to include context and merge nearby changes
        self.expand_and_merge_regions(new_content, changes)
    }

    /// Expand change regions to include context and merge nearby regions
    fn expand_and_merge_regions(
        &self,
        content: &[u8],
        regions: Vec<(usize, usize)>,
    ) -> Vec<(usize, usize)> {
        if regions.is_empty() {
            return regions;
        }

        let mut expanded = Vec::with_capacity(regions.len());

        for (start, end) in regions {
            // Expand to include context
            let expanded_start = start.saturating_sub(CHANGE_CONTEXT_SIZE);
            let expanded_end = (end + CHANGE_CONTEXT_SIZE).min(content.len());

            // Find element boundaries to avoid partial tags
            let boundary_start = find_tag_boundary_before(content, expanded_start);
            let boundary_end = find_tag_boundary_after(content, expanded_end);

            expanded.push((boundary_start, boundary_end));
        }

        // Merge overlapping regions
        expanded.sort_by_key(|r| r.0);
        let mut merged = Vec::new();
        let mut current = expanded[0];

        for &(start, end) in &expanded[1..] {
            if start <= current.1 + 1024 {
                // Merge if regions are close
                current.1 = current.1.max(end);
            } else {
                merged.push(current);
                current = (start, end);
            }
        }
        merged.push(current);

        merged
    }

    /// Parse only the changed regions and merge with cached data
    fn parse_changed_regions(
        &mut self,
        content: &[u8],
        changed_regions: &[(usize, usize)],
        capacity_hint: usize,
    ) -> ExtractedClasses {
        let mut all_classes = AHashSet::with_capacity(capacity_hint);
        let mut all_group_events = Vec::new();

        // Track which regions we've processed
        let mut processed_ranges = Vec::new();

        // Parse changed regions
        for &(start, end) in changed_regions {
            if start >= content.len() {
                continue;
            }
            let end = end.min(content.len());
            let region = &content[start..end];

            self.stats.bytes_parsed += region.len();

            let result = extract_classes_fast(region, 64);
            all_classes.extend(result.classes);
            all_group_events.extend(result.group_events);

            processed_ranges.push((start, end));
        }

        // Reuse cached regions that haven't changed
        for cached_region in &self.regions {
            // Check if this cached region overlaps with any changed region
            let overlaps = processed_ranges
                .iter()
                .any(|&(start, end)| !(cached_region.end <= start || cached_region.start >= end));

            if !overlaps {
                // This region is still valid, reuse it
                all_classes.extend(cached_region.classes.iter().cloned());
                all_group_events.extend(cached_region.group_events.iter().cloned());

                self.stats.bytes_skipped += cached_region.end - cached_region.start;
                self.stats.regions_reused += 1;
            }
        }

        ExtractedClasses {
            classes: all_classes,
            group_events: all_group_events,
        }
    }

    /// Update cache with new parse results
    fn update_cache(&mut self, content: &[u8], hash: u64, result: &ExtractedClasses) {
        self.prev_hash = hash;
        self.prev_content = content.to_vec();

        // For simplicity, cache the entire file as one region
        // In a more advanced implementation, we'd split into multiple regions
        let region = RegionCache {
            start: 0,
            end: content.len(),
            content_hash: hash,
            classes: result.classes.clone(),
            group_events: result.group_events.clone(),
        };

        self.regions = vec![region];
    }

    /// Reconstruct result from cache (no changes detected)
    fn reconstruct_from_cache(&mut self) -> ExtractedClasses {
        let mut classes = AHashSet::new();
        let mut group_events = Vec::new();

        for region in &self.regions {
            classes.extend(region.classes.iter().cloned());
            group_events.extend(region.group_events.iter().cloned());
        }

        self.stats.bytes_skipped += self.prev_content.len();

        ExtractedClasses {
            classes,
            group_events,
        }
    }

    /// Reset the parser state
    #[allow(dead_code)]
    pub fn reset(&mut self) {
        self.prev_hash = 0;
        self.prev_content.clear();
        self.regions.clear();
    }

    /// Get current statistics
    pub fn stats(&self) -> &IncrementalStats {
        &self.stats
    }
}

/// Split content into lines with byte offsets
fn split_into_lines(content: &[u8]) -> Vec<(usize, usize)> {
    let mut lines = Vec::new();
    let mut start = 0;

    for (i, &byte) in content.iter().enumerate() {
        if byte == b'\n' {
            lines.push((start, i + 1));
            start = i + 1;
        }
    }

    if start < content.len() {
        lines.push((start, content.len()));
    }

    lines
}

/// Find the start of a complete HTML tag before the given position
fn find_tag_boundary_before(content: &[u8], pos: usize) -> usize {
    let mut i = pos;

    // Scan backwards to find a complete tag boundary
    while i > 0 {
        if content[i - 1] == b'>' {
            return i;
        }
        if i > 10 && content[i - 1] == b'<' {
            // Found opening tag, go back to previous closing tag
            i -= 1;
            continue;
        }
        i = i.saturating_sub(1);
    }

    0
}

/// Find the end of a complete HTML tag after the given position
fn find_tag_boundary_after(content: &[u8], pos: usize) -> usize {
    let mut i = pos;

    // Scan forwards to find a complete tag boundary
    while i < content.len() {
        if content[i] == b'>' {
            return (i + 1).min(content.len());
        }
        if content[i] == b'<' {
            // Found opening tag, continue to closing
            i += 1;
            continue;
        }
        i += 1;
    }

    content.len()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_incremental_parser_no_change() {
        let mut parser = IncrementalParser::new();
        let html = b"<div class=\"flex items-center\">Test</div>";

        // First parse
        let result1 = parser.parse_incremental(html, 0);
        assert!(result1.classes.contains("flex"));
        assert!(result1.classes.contains("items-center"));

        // Second parse with same content
        let result2 = parser.parse_incremental(html, 0);
        assert_eq!(result1.classes, result2.classes);
        assert_eq!(parser.stats.full_parses, 1);
        assert!(parser.stats.bytes_skipped > 0);
    }

    #[test]
    fn test_incremental_parser_small_change() {
        let mut parser = IncrementalParser::new();
        let html1 = b"<div class=\"flex items-center\">Test</div>";
        let html2 = b"<div class=\"flex items-center justify-between\">Test</div>";

        // First parse
        let result1 = parser.parse_incremental(html1, 0);
        assert_eq!(result1.classes.len(), 2);

        // Second parse with added class
        let result2 = parser.parse_incremental(html2, 0);
        assert_eq!(result2.classes.len(), 3);
        assert!(result2.classes.contains("justify-between"));
    }

    #[test]
    fn test_split_into_lines() {
        let content = b"line1\nline2\nline3";
        let lines = split_into_lines(content);

        assert_eq!(lines.len(), 3);
        assert_eq!(lines[0], (0, 6)); // "line1\n"
        assert_eq!(lines[1], (6, 12)); // "line2\n"
        assert_eq!(lines[2], (12, 17)); // "line3"
    }

    #[test]
    fn test_find_tag_boundaries() {
        let html = b"<div><span>text</span></div>";

        let boundary = find_tag_boundary_before(html, 10);
        assert!(boundary <= 10);

        let boundary = find_tag_boundary_after(html, 10);
        assert!(boundary >= 10);
    }

    #[test]
    fn test_incremental_stats() {
        let mut parser = IncrementalParser::new();
        let html1 = b"<div class=\"flex\">A</div>".repeat(100);
        let html2 = b"<div class=\"flex items-center\">A</div>".repeat(100);

        parser.parse_incremental(&html1, 0);
        assert_eq!(parser.stats.full_parses, 1);

        parser.parse_incremental(&html2, 0);
        // Should be incremental or full depending on change size
        assert!(parser.stats.full_parses > 0 || parser.stats.incremental_parses > 0);
    }
}
